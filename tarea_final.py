# -*- coding: utf-8 -*-
"""Tarea_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KkpjF4sWZYz32n0rZ8IU2IRqDs7RWlwR

---
##Trabajo colaborativo final


---
En función del dataset escogido trabajar en un proceso de clasificación de acuerdo a la variable target.

**Indicaciones de la tarea**
- Pueden trabajar la tarea de manera individual o grupal
- Pueden trabajar con un dataset de su elección o usar el datasets que se ha analizado en las clases (diabetes.csv)
- El notebook debe estar estructurado en las siguientes fases:
  1. Integrante(s) de grupo:
  - Anny Consuelo Arias Figueroa
  - Leonardo José Sullón Lévano
  2. Objetivo del análisis
  - Identificar cómo factores como la edad, el ejercicio, el sueño, la ingesta de azúcar, el consumo de alcohol y el tabaquismo influyen en el nivel de riesgo de salud.
  - Limpiar, codificar y escalar las variables numéricas y categóricas para preparar el dataset para los modelos de machine learning.
  - Entrenar y comparar al menos dos algoritmos de clasificación.
  - Utilizar métricas como accucary, recall, precision, F1-score y ROC-AUC para determinar cuál modelo tiene mejor desempeño.
  - Exportar el mejor modelo entrenado como archivo .pkl y un .csv con las predicciones realizadas, facilitando su futura integración o análisis.
  - Determinar cuálies caracteristicas del estilo de vida son más relevantes para predecir un riesgo alto de salud, aportando una visión preventiva en salud pública o bienestar personal.
  3. Formulación analítica: incluir el diccionario de datos
  4. Configuración inicial
  5. Recolección del dataset
  6. Análisis Exploratorio de Datos
  7. Transformación de Datos
  8. Modelado: al menos 2 modelos de clasificación revisados en las prácticas.
  9. Evaluación de modelos.
  10. Despliegue: a través de un modelo pkl y de un csv con los resultados de la clasificación. (revisar los notebooks de las clases 1 y 2)  

"""

import kagglehub
import pandas as pd

# Download latest version
path = kagglehub.dataset_download("miadul/lifestyle-and-health-risk-prediction")

print("Path to dataset files:", path)

df = pd.read_csv("/kaggle/input/lifestyle-and-health-risk-prediction/Lifestyle_and_Health_Risk_Prediction_Synthetic_Dataset.csv")
df.head()

"""# Formulación analítica + diccionario de datos"""

import pandas as pd

diccionario = pd.DataFrame([
    {"Variable":"age","Tipo":"numérica","Descripción":"Edad (años)","Notas":"aprox 18–80"},
    {"Variable":"weight","Tipo":"numérica","Descripción":"Peso (kg)","Notas":""},
    {"Variable":"height","Tipo":"numérica","Descripción":"Talla (cm)","Notas":""},
    {"Variable":"exercise","Tipo":"categórica","Descripción":"Nivel de ejercicio","Notas":"low/medium/high"},
    {"Variable":"sleep","Tipo":"numérica","Descripción":"Horas de sueño/día","Notas":"3–12 aprox."},
    {"Variable":"sugar_intake","Tipo":"categórica","Descripción":"Ingesta de azúcar","Notas":"low/medium/high"},
    {"Variable":"smoking","Tipo":"categórica","Descripción":"Hábito de fumar","Notas":"yes/no"},
    {"Variable":"alcohol","Tipo":"categórica","Descripción":"Consumo de alcohol","Notas":"yes/no"},
    {"Variable":"married","Tipo":"categórica","Descripción":"Estado civil","Notas":"yes/no"},
    {"Variable":"profession","Tipo":"categórica","Descripción":"Ocupación","Notas":"artist/teacher/..."},
    {"Variable":"bmi","Tipo":"numérica","Descripción":"Índice de masa corporal (kg/m²)","Notas":""},
    {"Variable":"health_risk","Tipo":"objetivo","Descripción":"Riesgo de salud","Notas":"low/medium/high"},
])
diccionario

"""# Configuración inicial"""

import os, warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,
                             roc_curve, accuracy_score, f1_score, precision_score, recall_score)
import joblib

RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

CSV_PATH = "Lifestyle_and_Health_Risk_Prediction_Synthetic_Dataset.csv"
TARGET_COL = "health_risk"

print("Configuración lista, archivo esperado: ", CSV_PATH)

"""#Recolección del dataset"""

df = pd.read_csv("/kaggle/input/lifestyle-and-health-risk-prediction/Lifestyle_and_Health_Risk_Prediction_Synthetic_Dataset.csv")
print("Dimensiones: ", df.shape)
display(df.head())
print("\nTipos de datos:")
print(df.dtypes)
print("\nValores únicos por columna (primeros 10): ")
for c in df.columns:
  uniq = df[c].unique()
  print(f" - {c}: {uniq[:10]}{"..." if len(uniq)>10 else ''}")

"""Análisis Exploratorio de Datos (EDA)"""

#Nulos
nulls = df.isna().sum(). sort_values(ascending=False)
print("Nulos por columna (solo > 0): ")
display(nulls[nulls>0])

#Balance de clases
if TARGET_COL not in df.columns:
  raise ValueError(f"No se encontro la columna objetivo: {TARGET_COL}")
print("\nBalance de clases (proporción):")
display(df[TARGET_COL].value_counts(normalize=True).rename('proportion'))

#Descripcion numerica
display(df.describe())

#Histogramas numericos
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
for col in num_cols:
  plt.figure()
  df[col].dropna().hist(bins=30)
  plt.title(f"Histograma de {col}")
  plt.xlabel(col); plt.ylabel("Frecuencia")
  plt.show()

"""#Transformación de datos"""

y = df[TARGET_COL].astype(str)
X = df.drop(columns=[TARGET_COL])

num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, num_cols),
        ("cat", categorical_transformer, cat_cols),
    ]
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE
)

print("X_train:", X_train.shape, "| X_test:", X_test.shape)
print("Numéricas:", num_cols)
print("Categóricas:", cat_cols)

"""#Modelado (2 modelos de clasificación)"""

# Dos modelos: Regresión Logística (multiclase) y Random Forest
logreg = Pipeline(steps=[
    ("prep", preprocessor),
    ("clf", LogisticRegression(max_iter=2000, multi_class="auto", random_state=RANDOM_STATE))
])

rf = Pipeline(steps=[
    ("prep", preprocessor),
    ("clf", RandomForestClassifier(n_estimators=400, random_state=RANDOM_STATE))
])

# Validación cruzada (F1-macro)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)

def cv_metric(model, X, y, scoring="f1_macro"):
    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)
    return scores.mean(), scores.std()

for name, model in {"LogisticRegression": logreg, "RandomForest": rf}.items():
    mean_f1, std_f1 = cv_metric(model, X_train, y_train, scoring="f1_macro")
    print(f"{name} -> F1-macro CV: {mean_f1:.3f} ± {std_f1:.3f}")

"""#Evaluación de modelos"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,
                             roc_curve, accuracy_score, f1_score, precision_score, recall_score)
from sklearn.preprocessing import label_binarize

results = {}

def safe_roc_auc_ovr(y_true, y_proba, classes):
    """
    Calcula ROC-AUC OvR de forma segura (siempre que haya al menos 2 clases en y_true).
    Devuelve np.nan si no se puede calcular.
    """
    try:
        if y_proba is None:
            return np.nan
        if len(np.unique(y_true)) < 2:
            # No hay positivos/negativos suficientes en y_true
            return np.nan
        # y_proba shape debe coincidir con n_clases
        if y_proba.shape[1] != len(classes):
            return np.nan
        return roc_auc_score(y_true, y_proba, multi_class="ovr")
    except Exception:
        return np.nan

for name, model in {"LogisticRegression": logreg, "RandomForest": rf}.items():
    model.fit(X_train, y_train)
    y_pred  = model.predict(X_test)
    y_proba = model.predict_proba(X_test) if hasattr(model, "predict_proba") else None

    # Clases aprendidas por el clasificador (orden de columnas en predict_proba)
    if "clf" in model.named_steps:
        classes = model.named_steps["clf"].classes_
    else:
        classes = np.unique(y_train)

    # Métricas globales
    acc  = accuracy_score(y_test, y_pred)
    f1m  = f1_score(y_test, y_pred, average="macro", zero_division=0)
    f1w  = f1_score(y_test, y_pred, average="weighted", zero_division=0)
    prec = precision_score(y_test, y_pred, average="macro", zero_division=0)
    rec  = recall_score(y_test, y_pred, average="macro", zero_division=0)
    cm   = confusion_matrix(y_test, y_pred, labels=classes)

    auc_ovr = safe_roc_auc_ovr(y_test, y_proba, classes)

    results[name] = {
        "model": model, "acc": acc, "f1_macro": f1m, "f1_weighted": f1w,
        "precision_macro": prec, "recall_macro": rec, "auc_ovr": auc_ovr,
        "cm": cm, "classes": classes, "y_pred": y_pred, "y_proba": y_proba
    }

    print(f"\n {name}")
    print(f"Accuracy: {acc:.3f} | F1-macro: {f1m:.3f} | F1-weighted: {f1w:.3f} | ROC AUC OvR: {auc_ovr:.3f}")
    print("\nClassification report:")
    print(classification_report(y_test, y_pred, zero_division=0))

    # Matriz de confusión (orden consistente con 'classes')
    plt.figure()
    plt.matshow(cm, fignum=0)
    plt.title(f"Matriz de confusión — {name}")
    plt.xlabel("Predicho"); plt.ylabel("Real")
    plt.xticks(range(len(classes)), classes, rotation=45)
    plt.yticks(range(len(classes)), classes)
    plt.colorbar()
    plt.show()

    # ===== Curvas ROC =====
    # Solo si hay predict_proba y al menos 2 clases en y_test
    if (y_proba is not None) and (len(np.unique(y_test)) >= 2):
        # Caso BINARIO (2 clases): tomar la columna de la clase "positiva"
        if len(classes) == 2:
            # Elige como positiva la clase minoritaria en y_test (más informativa)
            vals, counts = np.unique(y_test, return_counts=True)
            minority_class = vals[np.argmin(counts)]
            try:
                pos_idx = list(classes).index(minority_class)
            except ValueError:
                # fallback: usa la segunda columna
                pos_idx = 1 if y_proba.shape[1] > 1 else 0

            # Verifica que haya ambos estados (pos/neg) para la curva
            y_bin = (y_test == classes[pos_idx]).astype(int)
            if y_bin.sum() > 0 and (y_bin == 0).sum() > 0 and y_proba.shape[1] > pos_idx:
                fpr, tpr, _ = roc_curve(y_bin, y_proba[:, pos_idx])
                plt.figure()
                plt.plot(fpr, tpr, label=f"Positiva: {classes[pos_idx]}")
                plt.plot([0,1],[0,1],'--')
                plt.xlabel("FPR"); plt.ylabel("TPR"); plt.title(f"ROC — {name} (binaria)")
                plt.legend()
                plt.show()

        # Caso MULTICLASE (>=3): OvR por clase, solo si y_test tiene positivos y negativos para esa clase
        elif len(classes) >= 3 and y_proba.shape[1] == len(classes):
            # Binariza contra cada clase, salta si y_test carece de positivos/negativos
            for i, cls in enumerate(classes):
                y_test_bin = (y_test == cls).astype(int)
                if y_test_bin.sum() == 0 or (y_test_bin == 0).sum() == 0:
                    # No se puede trazar ROC para esta clase en este split
                    continue
                fpr, tpr, _ = roc_curve(y_test_bin, y_proba[:, i])
                plt.figure()
                plt.plot(fpr, tpr, label=f"Clase {cls}")
                plt.plot([0,1],[0,1],'--')
                plt.xlabel("FPR"); plt.ylabel("TPR"); plt.title(f"ROC — {name} (OvR)")
                plt.legend()
                plt.show()

# Elegir mejor por F1-macro
best_name = max(results, key=lambda k: results[k]["f1_macro"])
best_model = results[best_name]["model"]
print(f"\n Mejor modelo por F1-macro: {best_name} ({results[best_name]['f1_macro']:.3f})")

"""#Despliegue"""

os.makedirs("outputs", exist_ok=True)

# Guardar modelo .pkl
pkl_path = os.path.join("outputs", f"best_model_{str(best_name)}.pkl")
joblib.dump(best_model, pkl_path)
print("Modelo guardado en:", pkl_path)

# CSV de predicciones y probabilidades
classes = results[best_name]["classes"]
y_pred  = results[best_name]["y_pred"]
y_proba = results[best_name]["y_proba"]

out_df = pd.DataFrame({
    "index": X_test.index,
    "y_true": y_test.values,
    "y_pred": y_pred
})

if y_proba is not None:
    for i, cls in enumerate(classes):
        out_df[f"proba_{cls}"] = y_proba[:, i]

csv_path = os.path.join("outputs", "predicciones_test.csv")
out_df.to_csv(csv_path, index=False)
print("Predicciones guardadas en:", csv_path)
out_df.head()